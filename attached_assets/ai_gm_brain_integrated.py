"""
AI GM Brain - Complete Integration with LLM Interaction Manager

Extends the AI GM Brain with LLM capabilities for NLU, advanced responses, and output delivery.
Enterprise AI GM Brain with full architecture integration
PostgreSQL + Vector DB + Langchain + OpenRouter
"""

import logging
import time
import asyncio
import uuid
import random
from typing import Dict, Any, List, Optional, Tuple, Union
from enum import Enum, auto
from dataclasses import dataclass
from datetime import datetime, timedelta

# Import existing narrative components
from narrative_context_manager import NarrativeContextManager
from world_state import WorldState, world_state_manager
from event_bus import EventType, GameEvent, event_bus
from template_processor_enhanced import TemplateProcessor
from narrative_branch_choice_handler import NarrativeBranchChoiceHandler
from ai_gm_dialogue_generator import AIGMDialogueGenerator

# Import text parser components
from text_parser import parse_input, ParsedCommand, parser_engine, vocabulary_manager, object_resolver
from game_context import game_context

# Import LLM components for Phase 2
from llm_interaction_manager import LLMInteractionManager, LLMProvider, PromptMode


class InputComplexity(Enum):
    """Categorizes input complexity to determine processing strategy."""
    SIMPLE_COMMAND = auto()      # Clear, parsed command
    CONVERSATIONAL = auto()      # Dialog, questions, complex interaction
    DISAMBIGUATION = auto()      # Needs player to choose between options
    PARSING_ERROR = auto()       # Parser couldn't understand input


class ProcessingMode(Enum):
    """Processing modes for different types of interactions."""
    MECHANICAL = auto()         # Template-based, fast responses via parser
    NARRATIVE = auto()         # Rich storytelling, moderate LLM usage
    INTERPRETIVE = auto()      # Heavy LLM usage for complex situations
    DISAMBIGUATION = auto()    # Handling parser disambiguation


class AIGMBrain:
    """
    The central AI GM orchestrator integrated with the text parser engine.
    """
    
    def __init__(self, 
                 game_id: str,
                 player_id: str = "player_character_id",
                 llm_client=None,  # Will be implemented in Phase 2
                 narrative_director=None):
        """
        Initialize the AI GM Brain with text parser integration.
        
        Args:
            game_id: Unique identifier for the game session
            player_id: ID of the primary player character
            llm_client: LLM client for complex narrative generation (Phase 2)
            narrative_director: Narrative director for branch handling
        """
        self.game_id = game_id
        self.player_id = player_id
        self.llm_client = llm_client
        
        # Initialize core components
        self.world_state = world_state_manager
        self.narrative_context = None  # Will be set after first context preparation
        self.context_manager = NarrativeContextManager(self.narrative_context, self.world_state)
        self.template_processor = TemplateProcessor()
        self.dialogue_generator = AIGMDialogueGenerator(self.template_processor)
        
        # Initialize branch handler if director provided
        self.branch_handler = None
        if narrative_director:
            self.branch_handler = NarrativeBranchChoiceHandler(narrative_director, event_bus)
        
        # Text parser integration - use the global instances
        self.parser_engine = parser_engine
        self.vocabulary = vocabulary_manager
        self.object_resolver = object_resolver
        self.game_context = game_context
        
        # Internal state tracking
        self.current_location = self.game_context.get_current_location()
        self.recent_events: List[GameEvent] = []
        self.active_conversations: Dict[str, Any] = {}
        self.processing_mode = ProcessingMode.MECHANICAL
        self.last_llm_interaction = None
        self.interaction_count = 0
        
        # Disambiguation state
        self.pending_disambiguation: Optional[ParsedCommand] = None
        
        # Configuration
        self.max_recent_events = 20
        self.llm_cooldown_seconds = 5
        self.conversational_keywords = {
            'question_words': ['what', 'where', 'when', 'why', 'how', 'who'],
            'conversational_starters': ['tell me', 'explain', 'describe', 'what about'],
            'social_actions': ['talk to', 'speak with', 'ask', 'greet', 'converse']
        }
        
        # Event subscriptions
        self._setup_event_listeners()
        
        # Logging
        self.logger = logging.getLogger(f"AIGMBrain_{game_id}")
        self.logger.info(f"AI GM Brain initialized for game {game_id} with text parser integration")
    
    def _setup_event_listeners(self):
        """Set up event listeners for relevant game events."""
        event_bus.subscribe(EventType.NARRATIVE_BRANCH_AVAILABLE, self._handle_narrative_opportunity)
        event_bus.subscribe(EventType.NPC_INTERACTION, self._handle_npc_interaction)
        event_bus.subscribe(EventType.LOCATION_ENTERED, self._handle_location_change)
        event_bus.subscribe(EventType.WORLD_STATE_CHANGED, self._handle_world_state_change)
        event_bus.subscribe(EventType.ACTION_PERFORMED, self._handle_action_performed)
        
        # Subscribe to parser events if they exist
        if hasattr(event_bus, 'subscribe'):
            try:
                event_bus.subscribe("PLAYER_COMMAND", self._handle_player_command)
            except:
                pass  # Event type might not be defined yet
    
    def process_player_input(self, input_string: str) -> Dict[str, Any]:
        """
        Main entry point for processing player input using the text parser.
        
        Args:
            input_string: Raw text input from the player
            
        Returns:
            Dictionary containing response data and metadata
        """
        self.interaction_count += 1
        start_time = time.time()
        
        self.logger.debug(f"Processing input #{self.interaction_count}: '{input_string}'")
        
        # Handle pending disambiguation first
        if self.pending_disambiguation:
            return self._handle_disambiguation_input(input_string, start_time)
        
        # Use the text parser to parse input
        try:
            parsed_command = parse_input(input_string, self.game_context.get_context())
        except Exception as e:
            self.logger.error(f"Parser error: {e}")
            return self._create_error_response("I'm having trouble understanding that. Could you try rephrasing?", start_time)
        
        # Determine complexity based on parser results
        complexity = self._analyze_parsed_command_complexity(parsed_command, input_string)
        
        # Route to appropriate processing method
        response_data = self._route_parsed_processing(parsed_command, complexity, input_string)
        
        # Add metadata
        processing_time = time.time() - start_time
        response_data['metadata'] = {
            'processing_time': processing_time,
            'complexity': complexity.name,
            'interaction_count': self.interaction_count,
            'processing_mode': self.processing_mode.name,
            'timestamp': datetime.utcnow().isoformat(),
            'parsed_successfully': not parsed_command.has_error(),
            'needs_disambiguation': parsed_command.needs_disambiguation()
        }
        
        return response_data
    
    def _handle_disambiguation_input(self, input_string: str, start_time: float) -> Dict[str, Any]:
        """Handle disambiguation choice from player."""
        if input_string.lower() == 'cancel':
            self.pending_disambiguation = None
            return {
                'response_text': "Disambiguation cancelled. What would you like to do?",
                'action_executed': False,
                'requires_llm': False,
                'processing_mode': 'disambiguation_cancelled',
                'metadata': {
                    'processing_time': time.time() - start_time,
                    'complexity': 'DISAMBIGUATION',
                    'interaction_count': self.interaction_count,
                    'processing_mode': 'DISAMBIGUATION',
                    'timestamp': datetime.utcnow().isoformat()
                }
            }
        
        try:
            choice_idx = int(input_string) - 1
            candidates = self.pending_disambiguation.disambiguation_candidates
            
            if 0 <= choice_idx < len(candidates):
                selected_candidate = candidates[choice_idx]
                
                # Update the command with the selected choice
                if self.pending_disambiguation.update_after_disambiguation(selected_candidate['id']):
                    command = self.pending_disambiguation
                    self.pending_disambiguation = None
                    
                    # Now process the resolved command
                    return self._process_resolved_command(command, start_time)
                else:
                    return self._create_error_response("Failed to resolve disambiguation.", start_time)
            else:
                return self._create_error_response("Invalid choice. Please enter a number from the list or 'cancel'.", start_time)
                
        except ValueError:
            return self._create_error_response("Please enter a number from the list or 'cancel'.", start_time)
    
    def _analyze_parsed_command_complexity(self, parsed_command: ParsedCommand, input_string: str) -> InputComplexity:
        """
        Analyze complexity based on parser results.
        
        Args:
            parsed_command: Result from text parser
            input_string: Original input string
            
        Returns:
            InputComplexity enum value
        """
        # Check for disambiguation needs
        if parsed_command.needs_disambiguation():
            return InputComplexity.DISAMBIGUATION
        
        # Check for parsing errors
        if parsed_command.has_error():
            return InputComplexity.PARSING_ERROR
        
        # Check for conversational patterns in original input
        input_lower = input_string.lower().strip()
        has_question = '?' in input_string or any(
            word in input_lower for word in self.conversational_keywords['question_words']
        )
        
        has_conversational = any(
            starter in input_lower for starter in self.conversational_keywords['conversational_starters']
        )
        
        # If parsed successfully but has conversational elements, it might need narrative handling
        if has_question or has_conversational:
            return InputComplexity.CONVERSATIONAL
        
        # Successfully parsed command - treat as simple
        return InputComplexity.SIMPLE_COMMAND
    
    def _route_parsed_processing(self, 
                                parsed_command: ParsedCommand, 
                                complexity: InputComplexity, 
                                input_string: str) -> Dict[str, Any]:
        """
        Route parsed command to appropriate processing method.
        
        Args:
            parsed_command: Parsed command from text parser
            complexity: Determined complexity level
            input_string: Original input string
            
        Returns:
            Response dictionary
        """
        if complexity == InputComplexity.SIMPLE_COMMAND:
            return self._process_parsed_command(parsed_command)
        elif complexity == InputComplexity.DISAMBIGUATION:
            return self._process_disambiguation_request(parsed_command)
        elif complexity == InputComplexity.CONVERSATIONAL:
            return self._process_conversational_with_parsing(parsed_command, input_string)
        else:  # PARSING_ERROR
            return self._handle_parsing_error(parsed_command, input_string)
    
    def _process_parsed_command(self, parsed_command: ParsedCommand) -> Dict[str, Any]:
        """
        Process a successfully parsed command.
        
        Args:
            parsed_command: Successfully parsed command
            
        Returns:
            Response dictionary
        """
        self.processing_mode = ProcessingMode.MECHANICAL
        
        # Execute the command using the parser engine
        try:
            command_dict = self.parser_engine.execute_command(parsed_command)
            
            # Get current context for response generation
            context = self._get_current_context()
            context['command'] = command_dict
            context['parsed_command'] = {
                'action': parsed_command.action,
                'direct_object': parsed_command.direct_object_phrase.noun if parsed_command.direct_object_phrase else None,
                'pattern': parsed_command.pattern.value if parsed_command.pattern else None
            }
            
            # Generate appropriate response based on action
            response_text = self._generate_action_response(parsed_command, context)
            
            return {
                'response_text': response_text,
                'action_executed': True,
                'requires_llm': False,
                'processing_mode': 'mechanical_parser',
                'command_details': command_dict
            }
            
        except Exception as e:
            self.logger.error(f"Error executing parsed command: {e}")
            return self._create_error_response("I couldn't complete that action right now.")
    
    def _process_disambiguation_request(self, parsed_command: ParsedCommand) -> Dict[str, Any]:
        """
        Process a command that needs disambiguation.
        
        Args:
            parsed_command: Command needing disambiguation
            
        Returns:
            Response dictionary with disambiguation options
        """
        self.processing_mode = ProcessingMode.DISAMBIGUATION
        self.pending_disambiguation = parsed_command
        
        # Format disambiguation options
        response_lines = [f"Error: {parsed_command.error_message}"]
        
        if parsed_command.disambiguation_candidates:
            for i, candidate in enumerate(parsed_command.disambiguation_candidates):
                desc = f"{i+1}. {candidate['name']}"
                if candidate.get('adjectives'):
                    desc += f" ({', '.join(candidate['adjectives'])})"
                if candidate.get('threat_tier'):
                    desc += f" [{candidate['threat_tier']}]"
                if candidate.get('location'):
                    desc += f" (in {candidate['location']})"
                response_lines.append(desc)
        
        response_lines.append("Enter the number of your choice, or 'cancel' to abort.")
        
        return {
            'response_text': '\n'.join(response_lines),
            'action_executed': False,
            'requires_llm': False,
            'processing_mode': 'disambiguation',
            'disambiguation_candidates': parsed_command.disambiguation_candidates
        }
    
    def _process_conversational_with_parsing(self, parsed_command: ParsedCommand, input_string: str) -> Dict[str, Any]:
        """
        Process conversational input that was partially parsed.
        
        Args:
            parsed_command: Partially parsed command
            input_string: Original input
            
        Returns:
            Response dictionary
        """
        self.processing_mode = ProcessingMode.NARRATIVE
        
        # Try to generate dialogue response first
        dialogue_response = self._attempt_dialogue_generation(input_string, parsed_command)
        
        if dialogue_response:
            return {
                'response_text': dialogue_response,
                'action_executed': False,
                'requires_llm': False,
                'processing_mode': 'narrative_dialogue'
            }
        else:
            # Mark for LLM processing (Phase 2)
            return {
                'response_text': self._generate_contextual_placeholder(parsed_command),
                'action_executed': False,
                'requires_llm': True,
                'processing_mode': 'needs_llm',
                'deferred_input': input_string,
                'partial_parse': parsed_command.to_command_dict() if parsed_command else None
            }
    
    def _handle_parsing_error(self, parsed_command: ParsedCommand, input_string: str) -> Dict[str, Any]:
        """
        Handle commands that couldn't be parsed.
        
        Args:
            parsed_command: Failed parse result
            input_string: Original input
            
        Returns:
            Response dictionary
        """
        self.processing_mode = ProcessingMode.INTERPRETIVE
        
        error_msg = parsed_command.error_message or "I don't understand that command."
        
        # Try to provide helpful suggestions
        suggestions = self._get_command_suggestions(input_string)
        
        if suggestions:
            response_text = f"{error_msg}\n\nDid you mean: {', '.join(suggestions)}?"
        else:
            response_text = f"{error_msg}\n\nTry commands like 'look', 'inventory', 'go north', or 'take [item]'."
        
        return {
            'response_text': response_text,
            'action_executed': False,
            'requires_llm': True,
            'processing_mode': 'parsing_error',
            'error': error_msg,
            'suggestions': suggestions
        }
    
    def _process_resolved_command(self, command: ParsedCommand, start_time: float) -> Dict[str, Any]:
        """Process a command after disambiguation resolution."""
        response = self._process_parsed_command(command)
        response['metadata'] = {
            'processing_time': time.time() - start_time,
            'complexity': 'DISAMBIGUATION',
            'interaction_count': self.interaction_count,
            'processing_mode': 'DISAMBIGUATION',
            'timestamp': datetime.utcnow().isoformat(),
            'disambiguation_resolved': True
        }
        return response
    
    def _generate_action_response(self, parsed_command: ParsedCommand, context: Dict[str, Any]) -> str:
        """
        Generate an appropriate response for an executed action.
        
        Args:
            parsed_command: The executed command
            context: Current game context
            
        Returns:
            Response text
        """
        action = parsed_command.action
        
        # Get action-specific template
        template = self._get_action_template(action, parsed_command, context)
        
        # Process template with current context
        try:
            return self.template_processor.process(template, context)
        except Exception as e:
            self.logger.error(f"Template processing error: {e}")
            return f"You {action}" + (f" the {parsed_command.direct_object_phrase.noun}" 
                                    if parsed_command.direct_object_phrase else "") + "."
    
    def _get_action_template(self, action: str, parsed_command: ParsedCommand, context: Dict[str, Any]) -> str:
        """
        Get appropriate template for an action.
        
        Args:
            action: Action verb
            parsed_command: The parsed command
            context: Current context
            
        Returns:
            Template string
        """
        # Enhanced templates based on parser patterns
        if action == "look" or action == "examine":
            if parsed_command.direct_object_phrase:
                return "You examine the {parsed_command.direct_object}. {IF command.direct_object_id}[Object description would go here]{ELSE}You don't see anything special about it.{ENDIF}"
            else:
                return "You look around. {IF location_context}The area {RANDOM[appears|seems|looks]} {location_context.dominant_aura}.{ELSE}You observe your surroundings carefully.{ENDIF}"
        
        elif action == "take" or action == "get":
            return "{IF command.success}You take the {parsed_command.direct_object}.{ELSE}You cannot take that right now.{ENDIF}"
        
        elif action == "go" or action == "move":
            if parsed_command.pattern and "DIRECTION" in parsed_command.pattern.value:
                return "{IF command.success}You head {parsed_command.direct_object}.{ELSE}You cannot go that way.{ENDIF}"
            else:
                return "{IF command.success}You move toward {parsed_command.direct_object}.{ELSE}You cannot reach that destination.{ENDIF}"
        
        elif action == "attack":
            return "{IF command.success}You attack the {parsed_command.direct_object}!{ELSE}You cannot attack that right now.{ENDIF}"
        
        elif action == "talk":
            return "You attempt to speak with {parsed_command.direct_object}."
        
        elif action == "inventory":
            return "You check your belongings. {IF player_inventory}You are carrying: {player_inventory_list}.{ELSE}You are not carrying anything.{ENDIF}"
        
        elif action == "use":
            return "{IF command.success}You use the {parsed_command.direct_object}.{ELSE}You cannot use that right now.{ENDIF}"
        
        # Default template
        return "You {action}{IF parsed_command.direct_object} the {parsed_command.direct_object}{ENDIF}."
    
    def _attempt_dialogue_generation(self, input_string: str, parsed_command: ParsedCommand = None) -> Optional[str]:
        """
        Attempt to generate dialogue response using existing dialogue system.
        
        Args:
            input_string: Player input
            parsed_command: Parsed command if available
            
        Returns:
            Generated dialogue or None if not applicable
        """
        # Check if there's an active NPC conversation
        if not self.active_conversations:
            return None
        
        # Check if the parsed command involves talking to someone
        if (parsed_command and parsed_command.action == "talk" and 
            parsed_command.direct_object_phrase and 
            parsed_command.direct_object_phrase.game_object_id):
            
            npc_id = parsed_command.direct_object_phrase.game_object_id
            context = self._get_current_context()
            
            # Generate dialogue based on context
            dialogue_themes = self._determine_dialogue_themes(context, npc_id)
            
            try:
                return self.dialogue_generator.generate_dialogue(
                    npc_id=npc_id,
                    dialogue_themes=dialogue_themes,
                    context=context,
                    player_id=self.player_id
                )
            except Exception as e:
                self.logger.error(f"Dialogue generation error: {e}")
                return None
        
        return None
    
    def _determine_dialogue_themes(self, context: Dict[str, Any], npc_id: str) -> List[str]:
        """Determine appropriate dialogue themes based on context."""
        themes = []
        
        # Check world state for themes
        world_state = context.get('world_state', {})
        if world_state.get('political_stability') in ['unrest', 'rebellion']:
            themes.append('caution')
        
        # Check relationship
        relationship = context.get('relationship', {})
        if relationship.get('quality') == 'negative':
            themes.append('suspicion')
        elif relationship.get('quality') == 'positive':
            themes.append('wisdom')
        
        # Default themes
        if not themes:
            themes = ['wisdom', 'tradition']
        
        return themes
    
    def _generate_contextual_placeholder(self, parsed_command: ParsedCommand = None) -> str:
        """Generate a contextual placeholder response."""
        if parsed_command and parsed_command.action:
            action_responses = {
                'talk': "I'm considering how to respond to your conversation...",
                'ask': "Let me think about your question...",
                'examine': "I'm looking more closely at that...",
                'look': "I'm taking in the details of your surroundings..."
            }
            return action_responses.get(parsed_command.action, "I'm processing your request...")
        
        return "I'm thinking about what you've said..."
    
    def _get_command_suggestions(self, input_string: str) -> List[str]:
        """Get command suggestions for failed parsing."""
        try:
            # Use the parser's suggestion system if available
            if hasattr(self.parser_engine, 'get_suggestions'):
                return self.parser_engine.get_suggestions(input_string)
            
            # Fallback to vocabulary manager suggestions
            words = input_string.lower().split()
            if words:
                first_word = words[0]
                suggestions = []
                
                # Check if it's close to a known verb
                for verb in self.vocabulary.verbs.keys():
                    if verb.startswith(first_word) or first_word in verb:
                        canonical = self.vocabulary.get_canonical_verb(verb)
                        if canonical not in suggestions:
                            suggestions.append(canonical)
                
                return suggestions[:3]  # Limit to 3 suggestions
                
        except Exception as e:
            self.logger.error(f"Error getting suggestions: {e}")
        
        return ["look", "inventory", "help"]
    
    def _create_error_response(self, message: str, start_time: float = None) -> Dict[str, Any]:
        """Create a standardized error response."""
        if start_time is None:
            start_time = time.time()
            
        return {
            'response_text': message,
            'action_executed': False,
            'requires_llm': False,
            'processing_mode': 'error',
            'metadata': {
                'processing_time': time.time() - start_time,
                'complexity': 'ERROR',
                'interaction_count': self.interaction_count,
                'processing_mode': 'ERROR',
                'timestamp': datetime.utcnow().isoformat()
            }
        }
    
    # Keep all the existing helper methods from the original implementation
    def _get_current_context(self) -> Dict[str, Any]:
        """Get comprehensive current context for template processing."""
        # Use game_context to get the current state
        game_ctx = self.game_context.get_context()
        
        # Create a basic event for context preparation
        dummy_event = type('Event', (), {
            'actor': self.player_id,
            'type': type('EventType', (), {'name': 'CONTEXT_REQUEST'})(),
            'context': {'location': game_ctx['current_location']}
        })()
        
        # Get narrative context
        narrative_ctx = self.context_manager.prepare_event_context(
            dummy_event,
            actor_id=self.player_id,
            location=game_ctx['current_location']
        )
        
        # Merge contexts
        narrative_ctx.update(game_ctx)
        
        return narrative_ctx
    
    # Event Handlers (keeping existing implementations)
    def _handle_narrative_opportunity(self, event: GameEvent):
        """Handle narrative branch opportunities."""
        self.logger.info(f"Narrative opportunity available: {event.context.get('branch_name')}")
        self.recent_events.append(event)
        self._trim_recent_events()
    
    def _handle_npc_interaction(self, event: GameEvent):
        """Handle NPC interaction events."""
        npc_id = event.context.get('target')
        if npc_id:
            self.active_conversations[npc_id] = {
                'started': event.timestamp,
                'last_interaction': event.timestamp,
                'context': event.context
            }
    
    def _handle_location_change(self, event: GameEvent):
        """Handle location change events."""
        new_location = event.context.get('location')
        if new_location:
            self.current_location = new_location
            self.game_context.set_current_location(new_location)
            self.logger.debug(f"Player moved to: {new_location}")
    
    def _handle_world_state_change(self, event: GameEvent):
        """Handle world state changes."""
        self.logger.info(f"World state changed: {event.context}")
        self.recent_events.append(event)
        self._trim_recent_events()
    
    def _handle_action_performed(self, event: GameEvent):
        """Handle action performed events."""
        self.recent_events.append(event)
        self._trim_recent_events()
    
    def _handle_player_command(self, event: GameEvent):
        """Handle player command events from the parser."""
        self.logger.debug(f"Player command executed: {event.context.get('command_details')}")
        self.recent_events.append(event)
        self._trim_recent_events()
    
    def _trim_recent_events(self):
        """Keep only the most recent events."""
        if len(self.recent_events) > self.max_recent_events:
            self.recent_events = self.recent_events[-self.max_recent_events:]
    
    # Utility Methods (keeping existing implementations with parser integration)
    def get_current_player_context(self) -> Dict[str, Any]:
        """Get current player context for external use."""
        return self._get_current_context()
    
    def get_pending_opportunities(self) -> List[Dict[str, Any]]:
        """Get pending narrative opportunities for the player."""
        if self.branch_handler:
            return self.branch_handler.get_pending_opportunities_for_gm(self.player_id)
        return []
    
    def get_world_state_summary(self) -> Dict[str, Any]:
        """Get current world state summary."""
        return self.world_state.get_current_state_summary()
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """Get processing statistics for monitoring."""
        return {
            'total_interactions': self.interaction_count,
            'current_mode': self.processing_mode.name,
            'recent_events_count': len(self.recent_events),
            'active_conversations': len(self.active_conversations),
            'current_location': self.current_location,
            'pending_disambiguation': self.pending_disambiguation is not None,
            'parser_vocabulary_loaded': self.vocabulary._monster_vocab_loaded
        }
    
    def get_parser_statistics(self) -> Dict[str, Any]:
        """Get text parser specific statistics."""
        return {
            'vocabulary_size': {
                'verbs': len(self.vocabulary.verbs),
                'nouns': len(self.vocabulary.nouns),
                'adjectives': len(self.vocabulary.adjectives),
                'monsters': len(self.vocabulary.monster_names),
                'compound_nouns': len(self.vocabulary.compound_nouns)
            },
            'game_context_objects': len(self.game_context._objects),
            'game_context_monsters': len(self.game_context._monsters),
            'current_location': self.game_context.get_current_location(),
            'in_combat': self.game_context.is_in_combat()
        }
    
    def set_narrative_director(self, narrative_director):
        """Set the narrative director and initialize branch handler."""
        self.branch_handler = NarrativeBranchChoiceHandler(narrative_director, event_bus)
        self.logger.info("Narrative director and branch handler initialized")
    
    def handle_game_event(self, event: GameEvent) -> Optional[Dict[str, Any]]:
        """Handle incoming game events and generate appropriate responses."""
        self.recent_events.append(event)
        self._trim_recent_events()
        
        if self._should_respond_to_event(event):
            return self._generate_event_response(event)
        
        return None
    
    def _should_respond_to_event(self, event: GameEvent) -> bool:
        """Determine if an event requires a GM response."""
        response_triggers = {
            EventType.LOCATION_ENTERED,
            EventType.NPC_INTERACTION,
            EventType.NARRATIVE_BRANCH_AVAILABLE,
            EventType.WORLD_STATE_CHANGED,
            EventType.COMBAT_STARTED,
            EventType.QUEST_COMPLETED
        }
        
        return event.type in response_triggers
    
    def _generate_event_response(self, event: GameEvent) -> Dict[str, Any]:
        """Generate appropriate response to a game event."""
        context = self._get_current_context()
        context['triggering_event'] = event.to_dict()
        
        template = self._get_event_template(event.type)
        response_text = self.template_processor.process(template, context)
        
        return {
            'response_text': response_text,
            'event_triggered': True,
            'requires_llm': False,
            'processing_mode': 'event_response'
        }
    
    def _get_event_template(self, event_type: EventType) -> str:
        """Get template for event responses."""
        templates = {
            EventType.LOCATION_ENTERED: "You enter {location}. {IF location_context.emotional_aura}The atmosphere feels {location_context.dominant_aura}.{ENDIF}",
            EventType.NPC_INTERACTION: "You encounter {target}.",
            EventType.NARRATIVE_BRANCH_AVAILABLE: "An opportunity presents itself...",
            EventType.WORLD_STATE_CHANGED: "Something has changed in the world around you.",
            EventType.COMBAT_STARTED: "Combat begins!",
            EventType.QUEST_COMPLETED: "You have completed a significant task."
        }
        
        return templates.get(event_type, "Something noteworthy has occurred.")
    
    def generate_gm_response(self, 
                           trigger_type: str = "general", 
                           context_override: Dict[str, Any] = None) -> Dict[str, Any]:
        """Generate a GM response for various triggers."""
        context = context_override or self._get_current_context()
        
        if trigger_type == "opportunity":
            opportunities = self.get_pending_opportunities()
            if opportunities:
                template = "As you consider your options, {RANDOM[you sense new possibilities|something draws your attention|you feel the weight of potential choices]}."
                response_text = self.template_processor.process(template, context)
                return {
                    'response_text': response_text,
                    'type': 'opportunity_hint',
                    'opportunities_available': len(opportunities)
                }
        
        elif trigger_type == "world_change":
            recent_world_events = [e for e in self.recent_events if e.type == EventType.WORLD_STATE_CHANGED]
            if recent_world_events:
                latest_change = recent_world_events[-1]
                template = "The winds of change stir around you. {description}"
                context['description'] = latest_change.context.get('description', 'Something fundamental has shifted.')
                response_text = self.template_processor.process(template, context)
                return {
                    'response_text': response_text,
                    'type': 'world_change_narration'
                }
        
        # General atmospheric response
        template = self._get_atmospheric_template()
        response_text = self.template_processor.process(template, context)
        
        return {
            'response_text': response_text,
            'type': 'atmospheric',
            'processing_mode': 'template'
        }
    
    def _get_atmospheric_template(self) -> str:
        """Get atmospheric description template."""
        templates = [
            "{IF time_of_day == 'evening'}The {current_season} evening settles around you.{ELIF time_of_day == 'morning'}The {current_season} morning brings new possibilities.{ELSE}The day continues in this {current_season} season.{ENDIF}",
            "{IF world_state.active_global_threats}Despite the {RANDOM[troubles|challenges|dangers]} facing the world, life continues.{ELSE}The world seems peaceful in this moment.{ENDIF}",
            "{IF location_context.emotional_aura} The {location_context.dominant_aura} atmosphere of this place affects your mood.{ELSE}You take a moment to observe your surroundings.{ENDIF}"
        ]
        
        import random
        return random.choice(templates)


class AIGMBrainPhase2(AIGMBrain):
    """
    Enhanced AI GM Brain with LLM integration for Phase 2.
    """
    
    def __init__(self, 
                 game_id: str,
                 player_id: str = "player_character_id",
                 llm_provider: LLMProvider = LLMProvider.OPENAI,
                 llm_api_key: str = None,
                 llm_model: str = "gpt-3.5-turbo",
                 narrative_director=None,
                 config=None):
        """
        Initialize Phase 2 AI GM Brain with LLM capabilities.
        
        Args:
            game_id: Unique identifier for the game session
            player_id: ID of the primary player character
            llm_provider: LLM provider to use
            llm_api_key: API key for LLM provider
            llm_model: LLM model to use
            narrative_director: Narrative director for branch handling
            config: Configuration object
        """
        # Initialize base AI GM Brain
        super().__init__(game_id, player_id, None, narrative_director)
        
        # Initialize LLM Interaction Manager
        self.llm_manager = LLMInteractionManager(
            provider=llm_provider,
            api_key=llm_api_key,
            model=llm_model,
            enable_cost_tracking=True
        )
        
        # LLM processing statistics
        self.llm_stats = {
            'nlu_requests': 0,
            'narrative_requests': 0,
            'dialogue_requests': 0,
            'total_llm_cost': 0.0,
            'average_response_time': 0.0
        }
        
        self.logger.info(f"AI GM Brain Phase 2 initialized with LLM provider: {llm_provider.value}")
    
    async def process_player_input_async(self, input_string: str) -> Dict[str, Any]:
        """
        Async version of process_player_input with LLM integration.
        
        Args:
            input_string: Raw text input from the player
            
        Returns:
            Dictionary containing response data and metadata
        """
        self.interaction_count += 1
        start_time = time.time()
        
        self.logger.debug(f"Processing input #{self.interaction_count} (async): '{input_string}'")
        
        # Handle pending disambiguation first (synchronous)
        if self.pending_disambiguation:
            return self._handle_disambiguation_input(input_string, start_time)
        
        # Use the text parser to parse input
        try:
            parsed_command = parse_input(input_string, self.game_context.get_context())
        except Exception as e:
            self.logger.error(f"Parser error: {e}")
            # Try LLM processing for parser failures
            return await self._process_with_llm_fallback(input_string, str(e), start_time)
        
        # Determine complexity based on parser results
        complexity = self._analyze_parsed_command_complexity(parsed_command, input_string)
        
        # Route to appropriate processing method (with LLM integration)
        response_data = await self._route_parsed_processing_async(parsed_command, complexity, input_string)
        
        # Add metadata
        processing_time = time.time() - start_time
        response_data['metadata'] = {
            'processing_time': processing_time,
            'complexity': complexity.name,
            'interaction_count': self.interaction_count,
            'processing_mode': self.processing_mode.name,
            'timestamp': datetime.utcnow().isoformat(),
            'parsed_successfully': not parsed_command.has_error(),
            'needs_disambiguation': parsed_command.needs_disambiguation(),
            'llm_used': response_data.get('llm_used', False)
        }
        
        # Update performance metrics
        self._update_performance_metrics(processing_time, 
                                       'llm' if response_data.get('llm_used') else 'template')
        
        return response_data
    
    async def _route_parsed_processing_async(self, 
                                           parsed_command, 
                                           complexity: InputComplexity, 
                                           input_string: str) -> Dict[str, Any]:
        """
        Async version of routing with LLM integration.
        
        Args:
            parsed_command: Parsed command from text parser
            complexity: Determined complexity level
            input_string: Original input string
            
        Returns:
            Response dictionary
        """
        if complexity == InputComplexity.SIMPLE_COMMAND:
            return self._process_parsed_command(parsed_command)
        elif complexity == InputComplexity.DISAMBIGUATION:
            return self._process_disambiguation_request(parsed_command)
        elif complexity == InputComplexity.CONVERSATIONAL:
            return await self._process_conversational_with_llm(parsed_command, input_string)
        else:  # PARSING_ERROR
            return await self._handle_parsing_error_with_llm(parsed_command, input_string)
    
    async def _process_conversational_with_llm(self, parsed_command, input_string: str) -> Dict[str, Any]:
        """
        Process conversational input using LLM for enhanced understanding.
        
        Args:
            parsed_command: Partially parsed command
            input_string: Original input
            
        Returns:
            Response dictionary
        """
        self.processing_mode = ProcessingMode.NARRATIVE
        
        # First try traditional dialogue generation
        dialogue_response = self._attempt_dialogue_generation(input_string, parsed_command)
        
        if dialogue_response:
            return {
                'response_text': dialogue_response,
                'action_executed': False,
                'requires_llm': False,
                'processing_mode': 'narrative_dialogue',
                'llm_used': False
            }
        
        # Use LLM for complex conversational processing
        try:
            context = self._get_current_context()
            context['parsed_command_action'] = parsed_command.action if parsed_command else None
            
            # Determine if this is a narrative request or dialogue
            if self._is_dialogue_request(input_string, context):
                llm_response = await self.llm_manager.generate_dialogue(
                    npc_id=self._extract_target_npc(parsed_command, context),
                    player_input=input_string,
                    context=context
                )
                response_type = 'llm_dialogue'
            else:
                llm_response = await self.llm_manager.generate_narrative(
                    narrative_request=input_string,
                    context=context
                )
                response_type = 'llm_narrative'
            
            if llm_response.success:
                self.llm_stats['narrative_requests'] += 1
                self._update_llm_stats(llm_response)
                
                return {
                    'response_text': llm_response.content,
                    'action_executed': False,
                    'requires_llm': False,
                    'processing_mode': response_type,
                    'llm_used': True,
                    'llm_metadata': {
                        'tokens_used': llm_response.tokens_used,
                        'cost_estimate': llm_response.cost_estimate,
                        'response_time': llm_response.response_time
                    }
                }
            else:
                # Fallback to template response
                return {
                    'response_text': self._generate_contextual_placeholder(parsed_command),
                    'action_executed': False,
                    'requires_llm': False,
                    'processing_mode': 'llm_fallback',
                    'llm_used': False,
                    'error': llm_response.error_message
                }
                
        except Exception as e:
            self.logger.error(f"LLM processing error: {e}")
            return {
                'response_text': self._generate_contextual_placeholder(parsed_command),
                'action_executed': False,
                'requires_llm': False,
                'processing_mode': 'llm_error',
                'llm_used': False,
                'error': str(e)
            }
    
    async def _handle_parsing_error_with_llm(self, parsed_command, input_string: str) -> Dict[str, Any]:
        """
        Handle parsing errors using LLM for NLU (Natural Language Understanding).
        
        Args:
            parsed_command: Failed parse result
            input_string: Original input
            
        Returns:
            Response dictionary with LLM-enhanced understanding
        """
        self.processing_mode = ProcessingMode.INTERPRETIVE
        
        try:
            # Get current context
            context = self._get_current_context()
            
            # Use LLM for NLU on parser failure
            llm_response = await self.llm_manager.understand_failed_input(
                raw_input=input_string,
                parser_error=parsed_command.error_message or "Unable to parse command",
                context=context
            )
            
            if llm_response.success and llm_response.parsed_json:
                self.llm_stats['nlu_requests'] += 1
                self._update_llm_stats(llm_response)
                
                # Process LLM understanding
                return await self._process_llm_nlu_result(llm_response.parsed_json, input_string, context)
            else:
                # Fallback to traditional error handling
                return self._handle_parsing_error_fallback(parsed_command, input_string)
                
        except Exception as e:
            self.logger.error(f"LLM NLU processing error: {e}")
            return self._handle_parsing_error_fallback(parsed_command, input_string)
    
    async def _process_llm_nlu_result(self, 
                                    nlu_result: Dict[str, Any], 
                                    input_string: str, 
                                    context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process the results of LLM NLU analysis.
        
        Args:
            nlu_result: Parsed JSON result from LLM
            input_string: Original input string
            context: Current game context
            
        Returns:
            Response dictionary based on LLM understanding
        """
        intent_summary = nlu_result.get('player_intent_summary', 'Unknown intent')
        aligned_opportunity = nlu_result.get('aligned_opportunity_id')
        aligned_action = nlu_result.get('aligned_branch_action')
        gm_acknowledgement = nlu_result.get('suggested_gm_acknowledgement', 'I understand.')
        confidence = nlu_result.get('confidence_score', 0.5)
        
        self.logger.info(f"LLM NLU Result - Intent: {intent_summary}, Confidence: {confidence}")
        
        # Handle aligned opportunities
        if aligned_opportunity and self.branch_handler:
            try:
                success, message, branch_id = self.branch_handler.attempt_to_initiate_branch_via_gm(
                    aligned_opportunity, self.player_id, self.game_id
                )
                
                if success:
                    return {
                        'response_text': f"{gm_acknowledgement}\n\n{message}",
                        'action_executed': True,
                        'requires_llm': False,
                        'processing_mode': 'llm_nlu_opportunity',
                        'llm_used': True,
                        'opportunity_initiated': aligned_opportunity,
                        'branch_id': branch_id
                    }
                else:
                    return {
                        'response_text': f"{gm_acknowledgement}\n\nHowever, {message}",
                        'action_executed': False,
                        'requires_llm': False,
                        'processing_mode': 'llm_nlu_opportunity_failed',
                        'llm_used': True
                    }
            except Exception as e:
                self.logger.error(f"Error initiating branch: {e}")
        
        # Handle aligned branch actions
        if aligned_action:
            # This would integrate with your narrative branch system
            self.logger.info(f"LLM identified branch action: {aligned_action}")
            
        # Default: Use GM acknowledgement
        return {
            'response_text': gm_acknowledgement,
            'action_executed': False,
            'requires_llm': False,
            'processing_mode': 'llm_nlu_acknowledgement',
            'llm_used': True,
            'nlu_result': nlu_result
        }
    
    async def _process_with_llm_fallback(self, input_string: str, error_message: str, start_time: float) -> Dict[str, Any]:
        """
        Process input with LLM as fallback when parser completely fails.
        
        Args:
            input_string: Original input
            error_message: Parser error message
            start_time: Processing start time
            
        Returns:
            Response dictionary
        """
        try:
            context = self._get_current_context()
            
            llm_response = await self.llm_manager.understand_failed_input(
                raw_input=input_string,
                parser_error=error_message,
                context=context
            )
            
            if llm_response.success and llm_response.parsed_json:
                result = await self._process_llm_nlu_result(llm_response.parsed_json, input_string, context)
                result['metadata'] = {
                    'processing_time': time.time() - start_time,
                    'complexity': 'PARSING_ERROR',
                    'interaction_count': self.interaction_count,
                    'processing_mode': 'LLM_FALLBACK',
                    'timestamp': datetime.utcnow().isoformat(),
                    'llm_used': True
                }
                return result
            else:
                return self._create_error_response(
                    "I'm having trouble understanding that. Could you try rephrasing?", 
                    start_time
                )
                
        except Exception as e:
            self.logger.error(f"LLM fallback processing error: {e}")
            return self._create_error_response(
                "I'm having trouble processing that right now. Please try again.", 
                start_time
            )
    
    def _handle_parsing_error_fallback(self, parsed_command, input_string: str) -> Dict[str, Any]:
        """Fallback error handling when LLM processing fails."""
        error_msg = parsed_command.error_message or "I don't understand that command."
        suggestions = self._get_command_suggestions(input_string)
        
        if suggestions:
            response_text = f"{error_msg}\n\nDid you mean: {', '.join(suggestions)}?"
        else:
            response_text = f"{error_msg}\n\nTry commands like 'look', 'inventory', 'go north', or 'take [item]'."
        
        return {
            'response_text': response_text,
            'action_executed': False,
            'requires_llm': False,
            'processing_mode': 'parsing_error_fallback',
            'error': error_msg,
            'suggestions': suggestions,
            'llm_used': False
        }
    
    def _is_dialogue_request(self, input_string: str, context: Dict[str, Any]) -> bool:
        """Determine if input is a dialogue request vs narrative request."""
        # Check if there's an active NPC conversation
        if self.active_conversations:
            return True
        
        # Check for social keywords
        social_keywords = ['talk', 'speak', 'ask', 'tell', 'say', 'greet']
        return any(keyword in input_string.lower() for keyword in social_keywords)
    
    def _extract_target_npc(self, parsed_command, context: Dict[str, Any]) -> str:
        """Extract target NPC ID from parsed command or context."""
        if (parsed_command and parsed_command.direct_object_phrase and 
            parsed_command.direct_object_phrase.game_object_id):
            return parsed_command.direct_object_phrase.game_object_id
        
        # Check active conversations
        if self.active_conversations:
            return list(self.active_conversations.keys())[0]
        
        return "unknown_npc"
    
    def _update_llm_stats(self, llm_response):
        """Update LLM usage statistics."""
        if llm_response.cost_estimate:
            self.llm_stats['total_llm_cost'] += llm_response.cost_estimate
        
        # Update average response time
        current_avg = self.llm_stats['average_response_time']
        total_requests = (self.llm_stats['nlu_requests'] + 
                         self.llm_stats['narrative_requests'] + 
                         self.llm_stats['dialogue_requests'])
        
        if total_requests > 0:
            self.llm_stats['average_response_time'] = (
                (current_avg * (total_requests - 1) + llm_response.response_time) / total_requests
            )
    
    def get_comprehensive_statistics(self) -> Dict[str, Any]:
        """Get comprehensive statistics including LLM usage."""
        base_stats = self.get_processing_statistics()
        llm_stats = self.get_llm_statistics()
        parser_stats = self.get_parser_statistics()
        performance_report = self.get_performance_report()
        
        return {
            'ai_gm_brain': base_stats,
            'llm_usage': llm_stats,
            'parser': parser_stats,
            'performance': performance_report,
            'timestamp': datetime.utcnow().isoformat()
        }
    
    def get_phase2_statistics(self) -> Dict[str, Any]:
        """Get Phase 2 specific statistics"""
        base_stats = self.get_comprehensive_statistics()
        
        # Add Phase 2 specific data if available
        return {
            **base_stats,
            'phase2_features': {
                'llm_integration_active': True,
                'narrative_expansion_active': False,
                'dialogue_enhancement_active': False
            },
            'phase2_timestamp': datetime.utcnow().isoformat()
        }


class EnterpriseAIGMBrain:
    """
    Enterprise-grade AI GM Brain with full architecture integration
    """
    
    def __init__(self,
                 player_id: str,
                 database_url: str,
                 openrouter_api_key: str,
                 session_id: str = None,
                 default_llm_model: str = "anthropic/claude-3-sonnet"):
        """
        Initialize enterprise AI GM Brain.
        
        Args:
            player_id: Player identifier
            database_url: PostgreSQL connection string
            openrouter_api_key: OpenRouter API key
            session_id: Existing session ID or None to create new
            default_llm_model: Default LLM model to use
        """
        self.player_id = player_id
        
        # Initialize database service
        from database.services import DatabaseService
        self.db_service = DatabaseService(database_url)
        
        # Initialize or get game session
        if session_id:
            self.session_id = session_id
        else:
            self.session_id = self.db_service.create_game_session(player_id)
        
        # Initialize LLM manager
        from llm_integration.openrouter_llm import EnhancedLLMManager
        self.llm_manager = EnhancedLLMManager(
            api_key=openrouter_api_key,
            db_service=self.db_service,
            default_model=default_llm_model
        )
        
        # Initialize Langchain memory manager
        from langchain_integration.memory_manager import LangchainMemoryManager
        self.memory_manager = LangchainMemoryManager(self.db_service)
        
        # Initialize core AI GM Brain (from previous implementation)
        self.core_brain = AIGMBrain(
            game_id=self.session_id,
            player_id=player_id,
            llm_client=self.llm_manager
        )
        
        # State tracking
        self.interaction_counter = 0
        self.current_conversation_id = None
        
        # Logging
        self.logger = logging.getLogger(f"EnterpriseAIGMBrain_{self.session_id}")
        self.logger.info(f"Enterprise AI GM Brain initialized for player {player_id}")
    
    async def process_player_input(self, input_string: str) -> Dict[str, Any]:
        """
        Process player input with full enterprise features.
        
        Args:
            input_string: Player's text input
            
        Returns:
            Comprehensive response with all metadata
        """
        start_time = datetime.utcnow()
        self.interaction_counter += 1
        
        # Update session activity
        self.db_service.update_session_activity(self.session_id)
        
        # Get current context from database
        context = await self._get_enhanced_context()
        
        try:
            # Use core brain for initial processing
            core_response = await self.core_brain.process_player_input_async(input_string)
            
            # Determine if we need enhanced LLM processing
            if core_response.get('requires_llm', False):
                enhanced_response = await self._process_with_enhanced_llm(
                    input_string, core_response, context
                )
            else:
                enhanced_response = core_response
            
            # Save interaction to database
            interaction_data = {
                'session_id': self.session_id,
                'interaction_number': self.interaction_counter,
                'player_input': input_string,
                'input_complexity': enhanced_response['metadata']['complexity'],
                'processing_mode': enhanced_response['metadata']['processing_mode'],
                'parser_success': enhanced_response['metadata'].get('parsed_successfully', False),
                'parsed_command': enhanced_response.get('command_details'),
                'disambiguation_needed': enhanced_response['metadata'].get('needs_disambiguation', False),
                'ai_response': enhanced_response['response_text'],
                'response_type': enhanced_response.get('processing_mode', 'unknown'),
                'llm_used': enhanced_response.get('llm_used', False),
                'processing_time': enhanced_response['metadata']['processing_time'],
                'tokens_used': enhanced_response.get('llm_metadata', {}).get('tokens_used', 0),
                'cost_estimate': enhanced_response.get('llm_metadata', {}).get('cost_estimate', 0.0),
                'created_at': start_time
            }
            
            interaction_id = self.db_service.save_interaction(interaction_data)
            
            # Save to vector memory for future retrieval
            if enhanced_response.get('llm_used', False):
                await self._save_to_vector_memory(input_string, enhanced_response, context)
            
            # Update conversation memory if applicable
            if self.current_conversation_id:
                await self._update_conversation_memory(input_string, enhanced_response)
            
            # Add enterprise metadata
            enhanced_response['enterprise_metadata'] = {
                'session_id': self.session_id,
                'interaction_id': interaction_id,
                'database_saved': True,
                'vector_memory_updated': enhanced_response.get('llm_used', False),
                'conversation_memory_updated': self.current_conversation_id is not None
            }
            
            return enhanced_response
            
        except Exception as e:
            self.logger.error(f"Error processing input: {e}")
            
            # Save error interaction
            error_interaction = {
                'session_id': self.session_id,
                'interaction_number': self.interaction_counter,
                'player_input': input_string,
                'ai_response': f"I apologize, but I encountered an error processing your request: {str(e)}",
                'response_type': 'error',
                'processing_time': (datetime.utcnow() - start_time).total_seconds(),
                'created_at': start_time
            }
            
            interaction_id = self.db_service.save_interaction(error_interaction)
            
            return {
                'response_text': error_interaction['ai_response'],
                'error': True,
                'error_message': str(e),
                'enterprise_metadata': {
                    'session_id': self.session_id,
                    'interaction_id': interaction_id,
                    'error_logged': True
                }
            }
    
    async def _get_enhanced_context(self) -> Dict[str, Any]:
        """Get enhanced context from database and memory systems."""
        # Get base context from core brain
        base_context = self.core_brain._get_current_context()
        
        # Get recent interactions
        recent_interactions = self.db_service.get_recent_interactions(self.session_id, 5)
        
        # Get recent events
        recent_events = self.db_service.get_recent_events(self.session_id, limit=10)
        
        # Get current world state
        world_state = self.db_service.get_current_world_state(self.session_id)
        
        # Get relevant context from vector memory
        if hasattr(self, '_last_query'):
            relevant_context = self.memory_manager.retrieve_relevant_context(
                self._last_query, self.session_id, limit=3
            )
        else:
            relevant_context = []
        
        # Enhance context
        enhanced_context = {
            **base_context,
            'recent_interactions': [
                {
                    'input': interaction.player_input,
                    'response': interaction.ai_response,
                    'timestamp': interaction.created_at.isoformat()
                }
                for interaction in recent_interactions
            ],
            'recent_events': [
                {
                    'type': event.event_type,
                    'context': event.context,
                    'timestamp': event.created_at.isoformat()
                }
                for event in recent_events
            ],
            'world_state': {
                'economic_status': world_state.economic_status if world_state else 'stable',
                'political_stability': world_state.political_stability if world_state else 'stable',
                'current_season': world_state.current_season if world_state else 'spring',
                'active_global_threats': world_state.active_global_threats if world_state else []
            } if world_state else {},
            'relevant_context': relevant_context,
            'session_stats': self.db_service.get_interaction_stats(self.session_id)
        }
        
        return enhanced_context
    
    async def _process_with_enhanced_llm(self, 
                                       input_string: str, 
                                       core_response: Dict[str, Any], 
                                       context: Dict[str, Any]) -> Dict[str, Any]:
        """Process input with enhanced LLM capabilities."""
        self._last_query = input_string
        
        # Determine optimal model based on complexity
        complexity = core_response['metadata']['complexity']
        task_type = self._determine_task_type(core_response)
        optimal_model = self.llm_manager.get_optimal_model(task_type, complexity.lower())
        
        try:
            # Get conversation chain if in dialogue mode
            if self._is_conversation_mode(core_response):
                if not self.current_conversation_id:
                    self.current_conversation_id = f"conv_{uuid.uuid4()}"
                
                chain = self.memory_manager.create_conversation_chain(
                    self.llm_manager.get_llm(optimal_model),
                    self.session_id,
                    self.current_conversation_id
                )
                
                response_content = chain.predict(input=input_string)
            else:
                # Direct LLM call for non-conversational tasks
                prompt = self._build_enhanced_prompt(input_string, core_response, context)
                
                llm_result = await self.llm_manager.call_llm_with_tracking(
                    prompt=prompt,
                    model=optimal_model,
                    prompt_mode=task_type
                )
                
                response_content = llm_result['content']
                
                # Add LLM metadata to response
                core_response['llm_metadata'] = {
                    'model_used': optimal_model,
                    'tokens_used': llm_result['tokens_used'],
                    'cost_estimate': llm_result['cost_estimate'],
                    'response_time': llm_result['response_time']
                }
            
            # Update response
            core_response['response_text'] = response_content
            core_response['llm_used'] = True
            core_response['enhanced_processing'] = True
            
            return core_response
            
        except Exception as e:
            self.logger.error(f"Enhanced LLM processing error: {e}")
            # Return original response with error note
            core_response['llm_error'] = str(e)
            return core_response
    
    def _determine_task_type(self, core_response: Dict[str, Any]) -> str:
        """Determine the type of LLM task based on core response."""
        processing_mode = core_response.get('processing_mode', '')
        
        if 'parsing_error' in processing_mode or 'nlu' in processing_mode:
            return 'nlu_parser_failure'
        elif 'dialogue' in processing_mode or 'conversation' in processing_mode:
            return 'dialogue_generation'
        elif 'narrative' in processing_mode:
            return 'narrative_generation'
        elif 'query' in processing_mode or 'world' in processing_mode:
            return 'world_query'
        else:
            return 'narrative_generation'
    
    def _is_conversation_mode(self, core_response: Dict[str, Any]) -> bool:
        """Check if we're in conversation mode."""
        processing_mode = core_response.get('processing_mode', '')
        return 'dialogue' in processing_mode or 'conversation' in processing_mode
    
    def _build_enhanced_prompt(self, 
                             input_string: str, 
                             core_response: Dict[str, Any], 
                             context: Dict[str, Any]) -> str:
        """Build enhanced prompt with full context."""
        task_type = self._determine_task_type(core_response)
        
        base_prompts = {
            'nlu_parser_failure': """You are an expert AI Game Master. The player's input couldn't be parsed by the game's command system.

Player Input: "{input_string}"
Parser Error: "{parser_error}"

Current Game Context:
{context_summary}

Recent Player Actions:
{recent_actions}

Please:
1. Understand the player's intent
2. Provide a helpful, immersive response
3. Suggest specific actions they could take
4. Maintain the fantasy RPG atmosphere

Response:""",
            
            'narrative_generation': """You are a masterful AI Game Master creating rich fantasy narrative content.

Player Request: "{input_string}"

Current Situation:
{context_summary}

World State:
{world_state}

Recent Context:
{relevant_context}

Generate an immersive, detailed narrative response that:
- Responds to the player's request
- Incorporates the current world state and atmosphere
- Maintains consistency with recent events
- Provides engaging sensory details and storytelling
- Suggests potential developments or opportunities

Response:""",
            
            'dialogue_generation': """You are an AI Game Master generating authentic NPC dialogue.

Player's Approach: "{input_string}"

NPC Context:
{npc_context}

Current Situation:
{context_summary}

Conversation History:
{conversation_history}

Generate authentic dialogue that:
- Reflects the NPC's personality and current mood
- Responds appropriately to the player's approach
- Incorporates relevant world events or local information
- Maintains character consistency
- Advances the narrative meaningfully

NPC Response:"""
        }
        
        prompt_template = base_prompts.get(task_type, base_prompts['narrative_generation'])
        
        # Format the prompt with context
        return prompt_template.format(
            input_string=input_string,
            parser_error=core_response.get('error', 'Unknown parsing error'),
            context_summary=self._format_context_summary(context),
            recent_actions=self._format_recent_actions(context),
            world_state=self._format_world_state(context),
            relevant_context=self._format_relevant_context(context),
            npc_context=self._format_npc_context(context),
            conversation_history=self._format_conversation_history(context)
        )
    
    def _format_context_summary(self, context: Dict[str, Any]) -> str:
        """Format context summary for prompts."""
        return f"""
Location: {context.get('location_name', 'Unknown')}
Time: {context.get('time_of_day', 'Unknown')} in {context.get('current_season', 'spring')}
Player Status: {context.get('player_status_summary', 'Alert and ready')}
"""
    
    def _format_recent_actions(self, context: Dict[str, Any]) -> str:
        """Format recent actions for prompts."""
        interactions = context.get('recent_interactions', [])[:3]
        if not interactions:
            return "No recent actions."
        
        return "\n".join([
            f"- Player: {interaction['input']} | Response: {interaction['response'][:100]}..."
            for interaction in interactions
        ])
    
    def _format_world_state(self, context: Dict[str, Any]) -> str:
        """Format world state for prompts."""
        world_state = context.get('world_state', {})
        return f"""
Economic Status: {world_state.get('economic_status', 'stable')}
Political Climate: {world_state.get('political_stability', 'stable')}
Active Threats: {', '.join(world_state.get('active_global_threats', []) or ['None'])}
"""
    
    def _format_relevant_context(self, context: Dict[str, Any]) -> str:
        """Format relevant context from vector memory."""
        relevant = context.get('relevant_context', [])
        if not relevant:
            return "No relevant previous context found."
        
        return "\n".join([
            f"- {item['content'][:100]}... (similarity: {item['similarity']:.2f})"
            for item in relevant
        ])
    
    def _format_npc_context(self, context: Dict[str, Any]) -> str:
        """Format NPC context for dialogue generation."""
        # This would be enhanced with actual NPC data
        return "NPC context would be populated from character database"
    
    def _format_conversation_history(self, context: Dict[str, Any]) -> str:
        """Format conversation history."""
        # This would pull from Langchain conversation memory
        return "Recent conversation context from Langchain memory"
    
    async def _save_to_vector_memory(self, 
                                   input_string: str, 
                                   response: Dict[str, Any], 
                                   context: Dict[str, Any]):
        """Save interaction to vector memory."""
        # Save player input
        self.memory_manager.save_to_vector_memory(
            session_id=self.session_id,
            content=input_string,
            content_type='player_input',
            metadata={
                'interaction_number': self.interaction_counter,
                'complexity': response['metadata']['complexity'],
                'timestamp': datetime.utcnow().isoformat()
            }
        )
        
        # Save AI response
        self.memory_manager.save_to_vector_memory(
            session_id=self.session_id,
            content=response['response_text'],
            content_type='ai_response',
            metadata={
                'interaction_number': self.interaction_counter,
                'processing_mode': response.get('processing_mode'),
                'llm_used': response.get('llm_used', False),
                'timestamp': datetime.utcnow().isoformat()
            }
        )
    
    async def _update_conversation_memory(self, input_string: str, response: Dict[str, Any]):
        """Update Langchain conversation memory."""
        if self.current_conversation_id:
            memory = self.memory_manager.get_conversation_memory(
                self.session_id, self.current_conversation_id
            )
            
            # Add messages to memory
            from langchain.schema import HumanMessage, AIMessage
            memory.chat_memory.add_message(HumanMessage(content=input_string))
            memory.chat_memory.add_message(AIMessage(content=response['response_text']))
    
    def get_comprehensive_analytics(self) -> Dict[str, Any]:
        """Get comprehensive analytics for the session."""
        return {
            'session_id': self.session_id,
            'player_id': self.player_id,
            'interaction_stats': self.db_service.get_interaction_stats(self.session_id),
            'llm_usage_stats': self.db_service.get_llm_usage_stats(self.session_id),
            'recent_events_count': len(self.db_service.get_recent_events(self.session_id, limit=20)),
            'current_conversation_active': self.current_conversation_id is not None,
            'total_interactions': self.interaction_counter
        }
    
    def end_session(self):
        """Properly end the game session."""
        # Mark session as inactive
        with self.db_service.get_session() as db:
            session = db.query(self.db_service.GameSession).filter(
                self.db_service.GameSession.id == self.session_id
            ).first()
            if session:
                session.is_active = False
                db.commit()
        
        self.logger.info(f"Session {self.session_id} ended")


class AIGMBrainPhase3(EnterpriseAIGMBrain):
    """
    Complete AI GM Brain with Phase 3 decision logic and mechanical integration
    """
    
    def __init__(self,
                 player_id: str,
                 database_url: str,
                 openrouter_api_key: str,
                 session_id: str = None,
                 default_llm_model: str = "anthropic/claude-3-sonnet",
                 narrative_director=None):
        """
        Initialize Phase 3 AI GM Brain with decision logic.
        
        Args:
            player_id: Player identifier
            database_url: PostgreSQL connection string
            openrouter_api_key: OpenRouter API key
            session_id: Existing session ID or None to create new
            default_llm_model: Default LLM model to use
            narrative_director: Narrative director for branch handling
        """
        # Initialize enterprise brain
        super().__init__(
            player_id=player_id,
            database_url=database_url,
            openrouter_api_key=openrouter_api_key,
            session_id=session_id,
            default_llm_model=default_llm_model
        )
        
        # Initialize decision engine
        from decision_logic.decision_tree import CoreDecisionEngine, DecisionContext, DecisionPriority
        from decision_logic.mechanical_integration import MechanicalOutcomesIntegrator
        
        self.decision_engine = CoreDecisionEngine(
            branch_handler=self.core_brain.branch_handler if self.core_brain.branch_handler else None,
            world_state_manager=self.core_brain.world_state,
            db_service=self.db_service
        )
        
        # Initialize mechanical outcomes integrator
        self.outcomes_integrator = MechanicalOutcomesIntegrator(
            template_processor=self.core_brain.template_processor
        )
        
        # Set narrative director if provided
        if narrative_director:
            self.core_brain.set_narrative_director(narrative_director)
            self.decision_engine.branch_handler = self.core_brain.branch_handler
        
        self.logger.info("AI GM Brain Phase 3 initialized with complete decision logic")
    
    async def process_player_input(self, input_string: str) -> Dict[str, Any]:
        """
        Process player input with complete Phase 3 decision logic.
        
        Args:
            input_string: Player's text input
            
        Returns:
            Comprehensive response with decision logic integration
        """
        start_time = datetime.utcnow()
        self.interaction_counter += 1
        
        # Update session activity
        self.db_service.update_session_activity(self.session_id)
        
        try:
            # Step 1: Get enhanced context
            context = await self._get_enhanced_context()
            
            # Step 2: Parse input using text parser
            parsed_command = await self._parse_input_with_error_handling(input_string, context)
            
            # Step 3: Get LLM interpretation if needed
            llm_output = await self._get_llm_interpretation_if_needed(
                input_string, parsed_command, context
            )
            
            # Step 4: Create decision context
            from decision_logic.decision_tree import DecisionContext
            decision_context = DecisionContext(
                session_id=self.session_id,
                player_id=self.player_id,
                raw_input=input_string,
                parsed_command=parsed_command,
                llm_output=llm_output,
                current_branch_id=await self._get_current_branch_id(),
                current_stage=await self._get_current_stage(),
                world_state=context.get('world_state'),
                player_context=context,
                pending_opportunities=await self._get_pending_opportunities()
            )
            
            # Step 5: Make decision using decision tree
            decision_result = self.decision_engine.make_decision(decision_context)
            
            # Step 6: Integrate mechanical outcomes into response
            final_response = self.outcomes_integrator.integrate_mechanical_outcome(
                decision_result, context
            )
            
            # Step 7: Save interaction and create response
            response_data = await self._create_comprehensive_response(
                input_string, decision_result, final_response, context, start_time
            )
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"Error in Phase 3 processing: {e}")
            return await self._create_error_response(input_string, str(e), start_time)
    
    async def _parse_input_with_error_handling(self, 
                                             input_string: str, 
                                             context: Dict[str, Any]) -> Optional[Any]:
        """Parse input with comprehensive error handling"""
        try:
            from text_parser import parse_input, ParsedCommand
            return parse_input(input_string, context)
        except Exception as e:
            self.logger.warning(f"Parser error: {e}")
            # Create error ParsedCommand-like object
            return type('ErrorCommand', (), {
                'raw_input': input_string,
                'error_message': str(e),
                'has_error': lambda: True,
                'action': None,
                'direct_object_phrase': None
            })()
    
    async def _get_llm_interpretation_if_needed(self, 
                                              input_string: str,
                                              parsed_command: Optional[Any],
                                              context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Get LLM interpretation when needed based on decision criteria"""
        needs_llm = False
        
        # Determine if LLM interpretation is needed
        if not parsed_command or (hasattr(parsed_command, 'has_error') and parsed_command.has_error()):
            needs_llm = True
            reason = "parser_failure"
        elif self._is_conversational_input(input_string):
            needs_llm = True
            reason = "conversational_input"
        elif self._is_ambiguous_input(parsed_command, input_string):
            needs_llm = True
            reason = "ambiguous_input"
        else:
            reason = "not_needed"
        
        if needs_llm:
            try:
                llm_result = await self.llm_manager.call_llm_with_tracking(
                    prompt=self._build_nlu_prompt(input_string, parsed_command, context),
                    model=self.llm_manager.get_optimal_model("nlu_parser_failure", "medium"),
                    prompt_mode="nlu_parser_failure"
                )
                
                if llm_result['success']:
                    # Parse JSON response
                    content = llm_result['content']
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    
                    if json_start >= 0 and json_end > json_start:
                        import json
                        json_str = content[json_start:json_end]
                        return json.loads(json_str)
                
            except Exception as e:
                self.logger.error(f"LLM interpretation error: {e}")
        
        return None
    
    def _build_nlu_prompt(self, 
                         input_string: str,
                         parsed_command: Optional[Any],
                         context: Dict[str, Any]) -> str:
        """Build NLU prompt for LLM interpretation"""
        parser_error = ""
        if parsed_command and hasattr(parsed_command, 'has_error') and parsed_command.has_error():
            parser_error = getattr(parsed_command, 'error_message', 'Unknown error')
        elif not parsed_command:
            parser_error = "Parser could not process input"
        else:
            parser_error = "Input may need interpretation"
        
        # Get pending opportunities
        pending_opportunities = context.get('pending_opportunities', [])
        
        # Format opportunities for prompt
        if pending_opportunities:
            opp_list = []
            for opp in pending_opportunities:
                opp_str = f"- Opportunity ID: \"{opp.get('_source_event_id_', 'unknown')}\", Name: \"{opp.get('branch_name', 'unknown')}\", Hook: \"{opp.get('description', 'No description')}\""
                opp_list.append(opp_str)
            opportunities_text = '\n'.join(opp_list)
        else:
            opportunities_text = "No pending opportunities available."
        
        # Build the prompt
        prompt = f"""You are a helpful AI Game Master assistant. The player's input could not be understood by the primary game parser.

Player Input: "{input_string}"
Parser Failure Reason (if any): "{parser_error}"

Current Game Context:
- Location: {context.get('location_name', 'Unknown Location')}
- Player Status: {context.get('player_status_summary', 'Alert and ready')}
- Time: {context.get('time_of_day', 'daytime')}
- Season: {context.get('current_season', 'spring')}
- World State: Economic status is {context.get('world_state', {}).get('economic_status', 'stable')}, political situation is {context.get('world_state', {}).get('political_stability', 'stable')}

Pending Narrative Opportunities for Player:
{opportunities_text}

Current Active Branch (if any):
- Branch Name: {context.get('active_branch_name', 'None')}
- Current Stage: {context.get('active_stage_name', 'None')} ({context.get('active_stage_description', 'None')})
- Available Actions in this Stage: {context.get('available_actions_list', 'No specific actions available')}

Recent Context:
{context.get('recent_events_summary', 'No recent significant events.')}

Based on the player's input and the context:
1. What is the player's most likely intent or question?
2. Does this intent strongly align with any of the PENDING NARRATIVE OPPORTUNITIES listed above? If yes, specify the Opportunity ID.
3. If in an ACTIVE BRANCH, does the intent strongly align with any of the AVAILABLE ACTIONS IN THIS STAGE? If yes, specify the action string.
4. If it does not align with a specific opportunity or action, briefly describe the general nature of their input (e.g., general query, roleplaying statement, observation).
5. Suggest a brief, in-character GM acknowledgment or response to the player that is helpful and maintains immersion.

Provide your response in JSON format like this:
{{
 "player_intent_summary": "Brief summary of player's likely intent.",
 "aligned_opportunity_id": "opportunity_id_string_or_null",
 "aligned_branch_action": "action_string_or_null",
 "input_nature_if_no_alignment": "description_or_null",
 "suggested_gm_acknowledgement": "GM's brief response to player.",
 "confidence_score": 0.8,
 "requires_followup": false
}}"""
        
        return prompt
    
    async def _get_current_branch_id(self) -> Optional[str]:
        """Get current active branch ID"""
        # This would integrate with your narrative branch system
        # For now, return None (no active branch)
        return None
    
    async def _get_current_stage(self) -> Optional[str]:
        """Get current stage of active branch"""
        # This would integrate with your narrative branch system
        return None
    
    async def _get_pending_opportunities(self) -> List[Dict[str, Any]]:
        """Get pending narrative opportunities"""
        if self.core_brain.branch_handler:
            return self.core_brain.branch_handler.get_pending_opportunities_for_gm(self.player_id)
        return []
    
    def _is_conversational_input(self, input_string: str) -> bool:
        """Check if input is conversational and needs LLM interpretation"""
        conversational_indicators = [
            'what', 'where', 'when', 'why', 'how', 'who', 'which',
            'tell me', 'explain', 'describe', 'what about', 'how about',
            'can you', 'could you', 'would you', 'do you know',
            'i think', 'i feel', 'i wonder', 'it seems', 'perhaps'
        ]
        
        input_lower = input_string.lower()
        return any(indicator in input_lower for indicator in conversational_indicators) or '?' in input_string
    
    def _is_ambiguous_input(self, parsed_command: Any, input_string: str) -> bool:
        """Check if parsed command is ambiguous and needs LLM clarification"""
        if not parsed_command or (hasattr(parsed_command, 'needs_disambiguation') and parsed_command.needs_disambiguation()):
            return True
        
        # Check for vague or unclear commands
        vague_actions = ['do', 'try', 'attempt', 'maybe', 'possibly']
        if hasattr(parsed_command, 'action') and parsed_command.action in vague_actions:
            return True
        
        # Check for missing critical information
        if (hasattr(parsed_command, 'action') and parsed_command.action in ['take', 'use', 'examine', 'talk'] and 
            not getattr(parsed_command, 'direct_object_phrase', None)):
            return True
        
        return False
    
    async def _create_comprehensive_response(self,
                                           input_string: str,
                                           decision_result,
                                           final_response: str,
                                           context: Dict[str, Any],
                                           start_time: datetime) -> Dict[str, Any]:
        """Create comprehensive response with all metadata"""
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        # Save interaction to database
        interaction_data = {
            'session_id': self.session_id,
            'interaction_number': self.interaction_counter,
            'player_input': input_string,
            'input_complexity': decision_result.priority_used.name,
            'processing_mode': decision_result.priority_used.name,
            'parser_success': (decision_result.metadata or {}).get('command_action') is not None,
            'parsed_command': decision_result.metadata,
            'disambiguation_needed': False,  # Handled in decision logic
            'ai_response': final_response,
            'response_type': decision_result.action_result.action_type if decision_result.action_result else 'general',
            'llm_used': bool(decision_result.metadata and decision_result.metadata.get('llm_confidence')),
            'processing_time': processing_time,
            'tokens_used': 0,  # Will be updated if LLM was used
            'cost_estimate': 0.0,
            'created_at': start_time
        }
        
        interaction_id = self.db_service.save_interaction(interaction_data)
        
        # Save decision event
        if self.db_service:
            self.db_service.save_event({
                'session_id': self.session_id,
                'event_type': 'DECISION_MADE',
                'actor': self.player_id,
                'context': {
                    'interaction_id': interaction_id,
                    'priority_used': decision_result.priority_used.name,
                    'action_type': decision_result.action_result.action_type if decision_result.action_result else None,
                    'action_outcome': decision_result.action_result.outcome.value if decision_result.action_result else None,
                    'mechanics_triggered': decision_result.action_result.mechanics_triggered if decision_result.action_result else False
                }
            })
        
        # Update vector memory
        await self._save_to_vector_memory(input_string, {
            'response_text': final_response,
            'llm_used': bool(decision_result.metadata and decision_result.metadata.get('llm_confidence')),
            'metadata': {'processing_mode': decision_result.priority_used.name}
        }, context)
        
        return {
            'response_text': final_response,
            'decision_priority': decision_result.priority_used.name,
            'action_executed': decision_result.action_result.mechanics_triggered if decision_result.action_result else False,
            'requires_followup': decision_result.requires_followup,
            'processing_mode': decision_result.priority_used.name,
            'action_result': {
                'outcome': decision_result.action_result.outcome.value if decision_result.action_result else None,
                'action_type': decision_result.action_result.action_type if decision_result.action_result else None,
                'details': decision_result.action_result.details if decision_result.action_result else {}
            },
            'metadata': {
                'session_id': self.session_id,
                'interaction_id': interaction_id,
                'processing_time': processing_time,
                'decision_metadata': decision_result.metadata or {},
                'narrative_enhancements_applied': len(decision_result.narrative_enhancements),
                'timestamp': datetime.utcnow().isoformat()
            },
            'enterprise_metadata': {
                'session_id': self.session_id,
                'interaction_id': interaction_id,
                'database_saved': True,
                'vector_memory_updated': True,
                'decision_engine_used': True,
                'mechanical_integration_applied': True
            }
        }
    
    async def _create_error_response(self,
                                   input_string: str,
                                   error_message: str,
                                   start_time: datetime) -> Dict[str, Any]:
        """Create error response for Phase 3 processing failures"""
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        # Save error interaction
        interaction_data = {
            'session_id': self.session_id,
            'interaction_number': self.interaction_counter,
            'player_input': input_string,
            'ai_response': f"I apologize, but I encountered an error processing your request: {error_message}",
            'response_type': 'error',
            'processing_time': processing_time,
            'created_at': start_time
        }
        
        interaction_id = self.db_service.save_interaction(interaction_data)
        
        return {
            'response_text': interaction_data['ai_response'],
            'error': True,
            'error_message': error_message,
            'decision_priority': 'ERROR',
            'action_executed': False,
            'requires_followup': True,
            'processing_mode': 'error_handling',
            'metadata': {
                'session_id': self.session_id,
                'interaction_id': interaction_id,
                'processing_time': processing_time,
                'error_type': 'phase3_processing_error',
                'timestamp': datetime.utcnow().isoformat()
            },
            'enterprise_metadata': {
                'session_id': self.session_id,
                'interaction_id': interaction_id,
                'error_logged': True
            }
        }
    
    def get_phase3_statistics(self) -> Dict[str, Any]:
        """Get Phase 3 specific statistics"""
        base_stats = self.get_comprehensive_statistics()
        
        # Add Phase 3 specific data if available
        return {
            **base_stats,
            'phase3_features': {
                'decision_tree_active': True,
                'mechanical_integration_active': True,
                'priority_routing_active': True,
                'narrative_branch_integration': self.decision_engine.branch_handler is not None
            },
            'phase3_timestamp': datetime.utcnow().isoformat()
        }


class AIGMBrainPhase4Complete(AIGMBrainPhase3):
    """
    Complete AI GM Brain with Phase 4 output generation and delivery
    """
    
    def __init__(self,
                 player_id: str,
                 database_url: str,
                 openrouter_api_key: str,
                 session_id: str = None,
                 default_llm_model: str = "anthropic/claude-3-sonnet",
                 narrative_director=None,
                 delivery_channels: List[str] = None):
        """
        Initialize complete AI GM Brain with Phase 4 capabilities.
        
        Args:
            player_id: Player identifier
            database_url: PostgreSQL connection string
            openrouter_api_key: OpenRouter API key
            session_id: Existing session ID or None to create new
            default_llm_model: Default LLM model to use
            narrative_director: Narrative director for branch handling
            delivery_channels: Preferred delivery channels
        """
        # Initialize Phase 3 brain
        super().__init__(
            player_id=player_id,
            database_url=database_url,
            openrouter_api_key=openrouter_api_key,
            session_id=session_id,
            default_llm_model=default_llm_model,
            narrative_director=narrative_director
        )
        
        # Initialize response generation engine
        from output_generation.response_generator import ResponseGenerationEngine, ResponseComplexity
        from output_generation.delivery_system import OutputDeliverySystem, DeliveryChannel, ResponsePriority
        
        self.response_generator = ResponseGenerationEngine(
            dialogue_generator=self.core_brain.dialogue_generator,
            template_processor=self.core_brain.template_processor,
            llm_manager=self.llm_manager,
            db_service=self.db_service
        )
        
        # Initialize output delivery system
        self.delivery_system = OutputDeliverySystem(db_service=self.db_service)
        
        # Set default delivery channels
        self.default_delivery_channels = delivery_channels or [
            'CONSOLE',
            'DATABASE_LOG'
        ]
        
        self.logger.info("AI GM Brain Phase 4 Complete initialized with output generation and delivery")
    
    async def process_player_input(self, input_string: str) -> Dict[str, Any]:
        """
        Complete player input processing with Phase 4 output generation and delivery.
        
        Args:
            input_string: Player's text input
            
        Returns:
            Complete response with delivery results
        """
        start_time = datetime.utcnow()
        
        try:
            # Phase 1-3: Process input through decision tree
            phase3_result = await super().process_player_input(input_string)
            
            # Extract decision result from Phase 3
            decision_result = self._extract_decision_result_from_phase3(phase3_result)
            
            # Get enhanced game context
            game_context = await self._get_enhanced_context()
            
            # Prepare interaction context
            interaction_context = {
                'session_id': self.session_id,
                'player_id': self.player_id,
                'interaction_id': phase3_result['enterprise_metadata']['interaction_id'],
                'raw_input': input_string
            }
            
            # Phase 4.1: Generate response
            response_generation_result = await self.response_generator.generate_response(
                decision_result=decision_result,
                game_context=game_context,
                interaction_context=interaction_context
            )
            
            # Phase 4.2: Deliver response
            delivery_result = await self.delivery_system.deliver_response(
                response_data=response_generation_result,
                metadata={
                    **phase3_result['metadata'],
                    'session_id': self.session_id,
                    'player_id': self.player_id,
                    'decision_priority': phase3_result.get('decision_priority'),
                    'processing_time': phase3_result['metadata']['processing_time']
                },
                channels=self.default_delivery_channels,
                priority=self._determine_delivery_priority(phase3_result)
            )
            
            # Combine all results
            complete_result = {
                **phase3_result,
                'final_response_text': response_generation_result['response_text'],
                'response_generation': response_generation_result,
                'delivery_result': delivery_result,
                'phase4_metadata': {
                    'response_generated': True,
                    'response_delivered': delivery_result['overall_success'],
                    'delivery_channels_used': delivery_result['successful_channels'],
                    'total_processing_time': (datetime.utcnow() - start_time).total_seconds(),
                    'phase4_complete': True
                }
            }
            
            return complete_result
            
        except Exception as e:
            self.logger.error(f"Error in Phase 4 complete processing: {e}")
            
            # Create error response and deliver it
            error_response = {
                'response_text': f"I apologize, but I encountered an error: {str(e)}",
                'response_source': 'error_fallback'
            }
            
            await self.delivery_system.deliver_response(
                response_data=error_response,
                metadata={
                    'session_id': self.session_id,
                    'player_id': self.player_id,
                    'error': True,
                    'error_message': str(e)
                },
                channels=['CONSOLE'],  # Safe fallback channel
                priority='IMMEDIATE'
            )
            
            return {
                'response_text': error_response['response_text'],
                'error': True,
                'error_message': str(e),
                'phase4_metadata': {
                    'response_generated': True,
                    'response_delivered': True,
                    'error_fallback_used': True,
                    'total_processing_time': (datetime.utcnow() - start_time).total_seconds(),
                    'phase4_complete': False
                }
            }
    
    def _extract_decision_result_from_phase3(self, phase3_result: Dict[str, Any]):
        """Extract decision result from Phase 3 output for Phase 4 processing"""
        # Create a simplified decision result object for Phase 4
        decision_result = type('DecisionResult', (), {
            'priority_used': type('Priority', (), {'name': phase3_result.get('decision_priority', 'UNKNOWN')})(),
            'action_result': type('ActionResult', (), {
                'outcome': type('Outcome', (), {'value': phase3_result.get('action_result', {}).get('outcome', 'unknown')})(),
                'action_type': phase3_result.get('action_result', {}).get('action_type', 'unknown'),
                'details': phase3_result.get('action_result', {}).get('details', {}),
                'mechanics_triggered': phase3_result.get('action_executed', False)
            })() if phase3_result.get('action_result') else None,
            'gm_response_base': phase3_result.get('response_text', ''),
            'narrative_enhancements': [],
            'requires_followup': phase3_result.get('requires_followup', False),
            'metadata': phase3_result.get('metadata', {})
        })()
        
        return decision_result
    
    def _determine_delivery_priority(self, phase3_result: Dict[str, Any]) -> str:
        """Determine delivery priority based on Phase 3 results"""
        priority_name = phase3_result.get('decision_priority', '')
        
        if priority_name in ['LLM_OPPORTUNITY_ALIGNMENT', 'LLM_BRANCH_ACTION_ALIGNMENT']:
            return 'HIGH'
        elif phase3_result.get('error', False):
            return 'IMMEDIATE'
        elif phase3_result.get('requires_followup', False):
            return 'HIGH'
        else:
            return 'NORMAL'
    
    def configure_delivery_channels(self, channels_config: Dict[str, Any]):
        """Configure delivery channels with specific settings"""
        
        # Configure web interface if specified
        if 'web_interface' in channels_config:
            web_config = channels_config['web_interface']
            self.delivery_system.configure_web_interface(
                websocket_manager=web_config.get('websocket_manager'),
                http_endpoint=web_config.get('http_endpoint')
            )
            if 'WEB_INTERFACE' not in self.default_delivery_channels:
                self.default_delivery_channels.append('WEB_INTERFACE')
        
        # Configure API endpoint if specified
        if 'api_endpoint' in channels_config:
            api_config = channels_config['api_endpoint']
            self.delivery_system.configure_api_endpoint(
                endpoint_url=api_config['url'],
                api_key=api_config.get('api_key')
            )
            if 'API_ENDPOINT' not in self.default_delivery_channels:
                self.default_delivery_channels.append('API_ENDPOINT')
        
        # Configure file logging if specified
        if 'file_log' in channels_config:
            file_config = channels_config['file_log']
            self.delivery_system.configure_file_logging(
                log_file_path=file_config['path'],
                format_json=file_config.get('format_json', True)
            )
            if 'FILE_LOG' not in self.default_delivery_channels:
                self.default_delivery_channels.append('FILE_LOG')
        
        self.logger.info(f"Configured delivery channels: {self.default_delivery_channels}")
    
    def get_comprehensive_phase6_statistics(self) -> Dict[str, Any]:
        """Get comprehensive statistics including all Phase 6 features"""
        
        # Get base Phase 5 statistics
        base_stats = self.get_phase5_comprehensive_statistics()
        
        # Get Phase 6 specific statistics
        pacing_stats = self.pacing_manager.get_pacing_statistics()
        npc_idle_stats = self.idle_npc_manager.get_idle_npc_statistics()
        summarization_stats = self.event_summarizer.get_summarization_statistics()
        
        return {
            **base_stats,
            'phase6_features': {
                'pacing_management': True,
                'ambient_storytelling': True,
                'idle_npc_behavior': True,
                'event_summarization': True,
                'cost_optimization': True
            },
            'pacing_statistics': pacing_stats,
            'npc_idle_statistics': npc_idle_stats,
            'summarization_statistics': summarization_stats,
            'phase6_performance': {
                'ambient_injections_per_hour': self._calculate_ambient_rate(),
                'npc_initiative_rate': self._calculate_npc_initiative_rate(),
                'summarization_efficiency': self._calculate_summarization_efficiency()
            },
            'system_maturity': {
                'all_phases_complete': True,
                'production_ready': True,
                'cost_optimized': True,
                'immersion_enhanced': True
            },
            'timestamp': datetime.utcnow().isoformat()
        }
    
    def _calculate_ambient_rate(self) -> float:
        """Calculate ambient injections per hour"""
        total_injections = self.pacing_manager.pacing_stats.get('total_ambient_injections', 0)
        # Simplified calculation - in production, use actual session duration
        return total_injections * 6  # Assume 10-minute session for demo
    
    def _calculate_npc_initiative_rate(self) -> float:
        """Calculate NPC initiative rate"""
        total_initiatives = getattr(self.idle_npc_manager, 'session_initiative_count', 0)
        return total_initiatives * 6  # Assume 10-minute session for demo
    
    def _calculate_summarization_efficiency(self) -> Dict[str, float]:
        """Calculate summarization efficiency metrics"""
        stats = self.event_summarizer.summarization_stats
        return {
            'tokens_saved_per_summary': stats.get('tokens_saved_estimate', 0) / max(1, stats.get('total_summaries_created', 1)),
            'events_per_summary': stats.get('events_summarized', 0) / max(1, stats.get('total_summaries_created', 1))
        }
    
    async def run_idle_check(self):
        """
        Periodic method to check for idle conditions and inject ambient content.
        This can be called by a background task or timer.
        """
        try:
            current_time = datetime.utcnow()
            time_since_last_input = current_time - self.last_input_time
            
            # Only check if player has been idle for a reasonable time
            if time_since_last_input >= timedelta(minutes=2):
                ambient_response = await self._check_and_inject_ambient_content(time_since_last_input)
                
                if ambient_response:
                    self.logger.info(f"Injected idle content: {ambient_response.get('ambient_trigger', 'unknown')}")
                    return ambient_response
            
            return None
            
        except Exception as e:
            self.logger.error(f"Error in idle check: {e}")
            return None
    
    async def force_story_summary(self) -> Optional[str]:
        """Force creation of a story summary (for testing or manual triggers)"""
        try:
            summary = await self.event_summarizer.create_summary(self.session_id)
            if summary:
                self.logger.info(f"Forced story summary created: {summary[:50]}...")
            return summary
        except Exception as e:
            self.logger.error(f"Error forcing story summary: {e}")
            return None


# Phase 6.4: Comprehensive Testing & Refinement System
class Phase6TestingSuite:
    """
    Comprehensive testing suite for Phase 6 features and overall system refinement
    """
    
    def __init__(self, brain: AIGMBrainPhase6Complete):
        self.brain = brain
        self.logger = logging.getLogger("Phase6TestingSuite")
        self.test_results = {}
    
    async def run_comprehensive_tests(self) -> Dict[str, Any]:
        """Run comprehensive tests of all Phase 6 features"""
        
        print(" Starting Phase 6 Comprehensive Testing Suite")
        print("=" * 60)
        
        test_suite = {
            'pacing_tests': await self._test_pacing_system(),
            'ambient_tests': await self._test_ambient_storytelling(),
            'npc_idle_tests': await self._test_npc_idle_behavior(),
            'summarization_tests': await self._test_event_summarization(),
            'integration_tests': await self._test_phase_integration(),
            'cost_optimization_tests': await self._test_cost_optimization(),
            'immersion_tests': await self._test_immersion_quality()
        }
        
        # Calculate overall results
        total_tests = sum(len(test_group) for test_group in test_suite.values())
        passed_tests = sum(
            sum(1 for test in test_group.values() if test.get('passed', False))
            for test_group in test_suite.values()
        )
        
        overall_results = {
            'test_suite_results': test_suite,
            'overall_stats': {
                'total_tests': total_tests,
                'passed_tests': passed_tests,
                'success_rate': passed_tests / max(1, total_tests),
                'system_ready': passed_tests / max(1, total_tests) >= 0.85
            },
            'recommendations': self._generate_recommendations(test_suite),
            'timestamp': datetime.utcnow().isoformat()
        }
        
        print(f"\n Testing Complete: {passed_tests}/{total_tests} tests passed")
        print(f"   Success Rate: {passed_tests/max(1, total_tests)*100:.1f}%")
        print(f"   System Ready: {' YES' if overall_results['overall_stats']['system_ready'] else ' NO'}")
        
        return overall_results
    
    async def _test_pacing_system(self) -> Dict[str, Any]:
        """Test pacing management system"""
        tests = {}
        
        # Test pacing state detection
        try:
            # Simulate different activity levels
            self.brain.pacing_manager.current_metrics.last_significant_event = datetime.utcnow() - timedelta(minutes=15)
            state = self.brain.pacing_manager._calculate_pacing_state()
            tests['pacing_state_detection'] = {
                'passed': hasattr(state, 'value'),
                'result': getattr(state, 'value', 'unknown'),
                'expected': 'lull or stagnant'
            }
        except Exception as e:
            tests['pacing_state_detection'] = {'passed': False, 'error': str(e)}
        
        # Test ambient content generation
        try:
            context = await self.brain._get_enhanced_context_with_reputation()
            should_inject, trigger = self.brain.pacing_manager.should_inject_ambient_content(context)
            tests['ambient_content_triggering'] = {
                'passed': isinstance(should_inject, bool),
                'should_inject': should_inject,
                'trigger': trigger if trigger else None
            }
        except Exception as e:
            tests['ambient_content_triggering'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_ambient_storytelling(self) -> Dict[str, Any]:
        """Test ambient storytelling features"""
        tests = {}
        
        # Test ambient content generation
        try:
            context = await self.brain._get_enhanced_context_with_reputation()
            context['current_location'] = 'Test Location'
            context['time_of_day'] = 'evening'
            
            # Use mock trigger
            mock_trigger = 'location_based'
            ambient_content = await self.brain.pacing_manager.generate_ambient_content(
                mock_trigger, context
            )
            
            tests['ambient_content_generation'] = {
                'passed': isinstance(ambient_content, str) and len(ambient_content) > 10,
                'content_length': len(ambient_content) if ambient_content else 0,
                'sample': ambient_content[:50] + "..." if ambient_content and len(ambient_content) > 50 else ambient_content
            }
        except Exception as e:
            tests['ambient_content_generation'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_npc_idle_behavior(self) -> Dict[str, Any]:
        """Test NPC idle behavior system"""
        tests = {}
        
        # Test NPC initiative logic
        try:
            context = await self.brain._get_enhanced_context_with_reputation()
            context['present_npcs'] = ['test_npc']
            context['npcs'] = {
                'test_npc': {
                    'name': 'Test Character',
                    'personality': 'friendly'
                }
            }
            
            should_initiate, theme = self.brain.idle_npc_manager.should_npc_initiate(
                'test_npc', context, timedelta(minutes=5)
            )
            
            tests['npc_initiative_logic'] = {
                'passed': isinstance(should_initiate, bool),
                'should_initiate': should_initiate,
                'dialogue_theme': theme
            }
        except Exception as e:
            tests['npc_initiative_logic'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_event_summarization(self) -> Dict[str, Any]:
        """Test event summarization system"""
        tests = {}
        
        # Test event addition and summarization logic
        try:
            # Add some test events
            test_event = {
                'event_type': 'NARRATIVE_BRANCH_INITIATED',
                'actor': 'test_player',
                'context': {'branch_name': 'Test Quest'}
            }
            
            self.brain.event_summarizer.add_event_for_summarization(test_event)
            
            tests['event_addition'] = {
                'passed': len(self.brain.event_summarizer.events_since_last_summary) > 0,
                'events_queued': len(self.brain.event_summarizer.events_since_last_summary)
            }
            
            # Test summarization readiness
            should_summarize = await self.brain.event_summarizer.should_create_summary()
            tests['summarization_logic'] = {
                'passed': isinstance(should_summarize, bool),
                'should_summarize': should_summarize
            }
            
        except Exception as e:
            tests['event_addition'] = {'passed': False, 'error': str(e)}
            tests['summarization_logic'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_phase_integration(self) -> Dict[str, Any]:
        """Test integration between all phases"""
        tests = {}
        
        # Test complete input processing
        try:
            test_inputs = [
                "look around the room",
                "I want to investigate the rumors about the haunted forest",
                "greet the barkeeper and ask about local news",
                # Simulate idle time for ambient content
                "wait quietly for a few minutes"
            ]
            
            successful_processes = 0
            for test_input in test_inputs:
                try:
                    response = await self.brain.process_player_input(test_input)
                    if response and 'response_text' in response:
                        successful_processes += 1
                except Exception:
                    pass
            
            tests['complete_input_processing'] = {
                'passed': successful_processes >= len(test_inputs) * 0.75,
                'successful_processes': successful_processes,
                'total_inputs': len(test_inputs)
            }
            
        except Exception as e:
            tests['complete_input_processing'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_cost_optimization(self) -> Dict[str, Any]:
        """Test cost optimization features"""
        tests = {}
        
        # Test LLM usage optimization
        try:
            stats = self.brain.get_comprehensive_phase6_statistics()
            
            # Check if template usage is higher than LLM usage (cost optimization)
            generation_stats = stats.get('response_generation_stats', {})
            template_usage = generation_stats.get('template_usage', 0)
            creative_llm_calls = generation_stats.get('llm_creative_calls', 0)
            
            tests['template_vs_llm_ratio'] = {
                'passed': template_usage >= creative_llm_calls,
                'template_usage': template_usage,
                'llm_usage': creative_llm_calls,
                'cost_optimized': template_usage >= creative_llm_calls
            }
            
        except Exception as e:
            tests['template_vs_llm_ratio'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    async def _test_immersion_quality(self) -> Dict[str, Any]:
        """Test immersion and storytelling quality"""
        tests = {}
        
        # Test response coherence and immersion
        try:
            test_response = await self.brain.process_player_input("look around thoughtfully")
            
            response_text = test_response.get('response_text', '')
            
            # Check for immersion indicators
            immersion_indicators = [
                len(response_text) > 20,  # Substantial response
                not response_text.startswith('Error'),  # No error messages
                '(OOC)' not in response_text,  # In-character response
                response_text.strip() != ''  # Non-empty response
            ]
            
            tests['response_immersion_quality'] = {
                'passed': sum(immersion_indicators) >= 3,
                'indicators_met': sum(immersion_indicators),
                'total_indicators': len(immersion_indicators),
                'sample_response': response_text[:100] + "..." if len(response_text) > 100 else response_text
            }
            
        except Exception as e:
            tests['response_immersion_quality'] = {'passed': False, 'error': str(e)}
        
        return tests
    
    def _generate_recommendations(self, test_suite: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on test results"""
        recommendations = []
        
        # Analyze test results and provide specific recommendations
        for test_category, tests in test_suite.items():
            failed_tests = [name for name, result in tests.items() if not result.get('passed', False)]
            
            if failed_tests:
                recommendations.append(f" {test_category}: Review {', '.join(failed_tests)}")
        
        # General recommendations
        if not recommendations:
            recommendations.append(" All systems functioning well - ready for production!")
        else:
            recommendations.append(" Focus on fixing failing tests before production deployment")
        
        return recommendations


# Fill in missing functions from earlier classes
def _update_performance_metrics(self, processing_time: float, mode: str):
    """Update performance metrics (placeholder)"""
    pass

def get_llm_statistics(self):
    """Get LLM statistics (placeholder)"""
    return {
        'total_requests': 0,
        'success_rate': 1.0,
        'average_cost': 0.0,
        'average_response_time': 0.0
    }

def get_performance_report(self):
    """Get performance report (placeholder)"""
    return {
        'average_processing_time': 0.1,
        'success_rate': 1.0,
        'error_rate': 0.0
    }

# Add missing methods to AIGMBrainPhase2
AIGMBrainPhase2._update_performance_metrics = _update_performance_metrics
AIGMBrainPhase2.get_llm_statistics = get_llm_statistics
AIGMBrainPhase2.get_performance_report = get_performance_report

# Add missing methods to base AIGMBrain
def _update_performance_metrics_base(self, processing_time: float, mode: str):
    """Update performance metrics for base class"""
    pass

AIGMBrain._update_performance_metrics = _update_performance_metrics_base

# Fill in missing functions for disambiguation and command processing
def _handle_disambiguation_selected_candidate(self, selected_candidate, command):
    """Handle selected disambiguation candidate"""
    if command.update_after_disambiguation(selected_candidate['id']):
        self.pending_disambiguation = None
        return self._process_resolved_command(command, time.time())
    else:
        return self._create_error_response("Failed to resolve disambiguation.")

def _format_disambiguation_candidate(self, candidate, index):
    """Format disambiguation candidate for display"""
    desc = f"{index}. {candidate['name']}"
    if candidate.get('adjectives'):
        desc += f" ({', '.join(candidate['adjectives'])})"
    if candidate.get('threat_tier'):
        desc += f" [{candidate['threat_tier']}]"
    if candidate.get('location'):
        desc += f" (in {candidate['location']})"
    return desc

def _get_parser_suggestions(self, input_string):
    """Get suggestions from parser"""
    if hasattr(self.parser_engine, 'get_suggestions'):
        return self.parser_engine.get_suggestions(input_string)
    
    # Fallback to vocabulary manager suggestions
    words = input_string.lower().split()
    if words:
        first_word = words[0]
        suggestions = []
        
        # Check if it's close to a known verb
        for verb in self.vocabulary.verbs.keys():
            if verb.startswith(first_word) or first_word in verb:
                canonical = self.vocabulary.get_canonical_verb(verb)
                if canonical not in suggestions:
                    suggestions.append(canonical)
        
        return suggestions[:3]  # Limit to 3 suggestions
    
    return []

def _generate_dialogue_response(self, npc_id, context, dialogue_themes):
    """Generate dialogue response"""
    try:
        return self.dialogue_generator.generate_dialogue(
            npc_id=npc_id,
            dialogue_themes=dialogue_themes,
            context=context,
            player_id=self.player_id
        )
    except Exception as e:
        self.logger.error(f"Dialogue generation error: {e}")
        return None

# Example usage and final demonstration
async def demonstrate_phase6_complete():
    """Complete demonstration of Phase 6 AI GM Brain"""
    
    print(" AI GM Brain Phase 6 Complete - Final Demonstration")
    print("=" * 60)
    print(f" Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")
    print(f" User: Comprehensive System Test")
    print("=" * 60)
    
    # Initialize complete system
    brain = AIGMBrainPhase6Complete(
        player_id="demo_player",
        database_url="postgresql://user:pass@localhost/ai_gm_db",
        openrouter_api_key="your_openrouter_key",
        session_id=None  # Create new session
    )
    
    print("\n System Initialization Complete")
    print("    Enterprise foundation (PostgreSQL + Vector DB)")
    print("    Phase 1: Text parsing & NLU")
    print("    Phase 2: LLM integration")  
    print("    Phase 3: Decision logic & action mapping")
    print("    Phase 4: Output generation & delivery")
    print("    Phase 5: World reaction & dynamic storytelling")
    print("    Phase 6: Pacing, ambient storytelling & refinements")
    
    # Demonstrate key scenarios
    scenarios = [
        "look around the tavern",
        "I want to investigate the rumors about the haunted forest",
        "greet the barkeeper and ask about local news",
        # Simulate idle time for ambient content
        "wait quietly for a few minutes"
    ]
    
    print(f"\n Running {len(scenarios)} demonstration scenarios...")
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n--- Scenario {i}: '{scenario}' ---")
        
        try:
            # Add some delay to simulate real gameplay
            if "wait quietly" in scenario:
                print("   [Simulating 5 minutes of idle time...]")
                brain.last_input_time = datetime.utcnow() - timedelta(minutes=5)
                ambient_response = await brain.run_idle_check()
                if ambient_response:
                    print(f"    Ambient: {ambient_response['response_text']}")
                continue
            
            response = await brain.process_player_input(scenario)
            
            print(f"    Response: {response['response_text'][:100]}...")
            print(f"    Mode: {response.get('processing_mode', 'unknown')}")
            print(f"    Time: {response.get('metadata', {}).get('processing_time', 0):.3f}s")
            
            if response.get('ambient_injection'):
                print(f"    Ambient: {response.get('ambient_trigger', 'unknown')}")
            elif response.get('world_reaction_assessment'):
                print(f"    World Reaction: ")
            
            # Show response preview
            response_text = response.get('final_response_text', response.get('response_text', 'No response'))
            preview = response_text[:150] + "..." if len(response_text) > 150 else response_text
            print(f" Response Preview: {preview}")
            
        except Exception as e:
            print(f"    Error: {e}")
    
    # Run comprehensive testing
    print(f"\n Running Comprehensive Test Suite...")
    testing_suite = Phase6TestingSuite(brain)
    test_results = await testing_suite.run_comprehensive_tests()
    
    # Show final statistics
    print(f"\n Final System Statistics")
    print("=" * 40)
    
    stats = brain.get_comprehensive_phase6_statistics()
    
    print(f"Total Interactions: {stats.get('total_interactions', 0)}")
    print(f"Ambient Content Injected: {stats.get('pacing_statistics', {}).get('total_ambient_injections', 0)}")
    print(f"NPC Initiatives: {stats.get('npc_idle_statistics', {}).get('session_initiative_count', 0)}")
    print(f"Story Summaries Created: {stats.get('summarization_statistics', {}).get('total_summaries_created', 0)}")
    
    # Production readiness assessment
    system_ready = test_results['overall_stats']['system_ready']
    print(f"\n Production Readiness: {' READY' if system_ready else ' NEEDS WORK'}")
    
    if system_ready:
        print("\n AI GM Brain Phase 6 Complete - FULLY OPERATIONAL!")
        print("    Ready for production deployment")
        print("    Cost-optimized with intelligent LLM usage")  
        print("    Immersive storytelling with world reactions")
        print("    Dynamic pacing and ambient content")
        print("    Advanced NPC behavior and interactions")
        print("    Automatic event summarization")
        print("    Enterprise-grade persistence and analytics")
    
    return brain, test_results


if __name__ == "__main__":
    # Run appropriate test based on what's available
    try:
        asyncio.run(demonstrate_phase6_complete())
    except Exception as e:
        print(f"Phase 6 demonstration error: {e}")
        print("Falling back to Phase 5 test...")
        try:
            asyncio.run(test_phase5_world_reaction())
        except Exception as e2:
            print(f"Phase 5 testing also failed: {e2}")
            print("System may need dependency setup")